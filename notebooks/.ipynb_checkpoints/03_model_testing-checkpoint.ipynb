{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee264b3d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/best_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     32\u001b[39m sns.set_palette(\u001b[33m\"\u001b[39m\u001b[33mviridis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# ## Load Models and Data\u001b[39;00m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Load the best model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m best_model = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../models/best_model.joblib\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m scaler = joblib.load(\u001b[33m'\u001b[39m\u001b[33m../models/scaler.joblib\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Load test data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/revolution_risk_predictor/venv/lib/python3.13/site-packages/joblib/numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../models/best_model.joblib'"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: light\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.14.5\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# # Revolution Risk Predictor - Model Testing\n",
    "# \n",
    "# This notebook tests the trained model with new inputs and provides model interpretation.\n",
    "\n",
    "# ## Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# ## Load Models and Data\n",
    "\n",
    "# Load the best model\n",
    "best_model = joblib.load('../models/best_model.joblib')\n",
    "scaler = joblib.load('../models/scaler.joblib')\n",
    "\n",
    "# Load test data\n",
    "X_test = pd.read_csv('../data/X_test.csv')\n",
    "y_test = pd.read_csv('../data/y_test.csv').iloc[:, 0]  # FIXED: Get first column as Series\n",
    "\n",
    "print(\"Models and data loaded successfully!\")\n",
    "print(f\"Best model type: {type(best_model).__name__}\")\n",
    "\n",
    "# ## Model Performance on Test Set\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, \"predict_proba\") else best_model.decision_function(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ## Test with Custom Inputs\n",
    "\n",
    "# Define feature names\n",
    "feature_names = ['log_gdp', 'unemployment', 'youth_pct', 'internet_pct', 'polity', 'prev_events']\n",
    "\n",
    "# Create test cases\n",
    "test_cases = [\n",
    "    # High risk case (low GDP, high unemployment, low polity, etc.)\n",
    "    {\n",
    "        'gdp': 5000,  # Low GDP\n",
    "        'unemployment': 15.0,  # High unemployment\n",
    "        'youth_pct': 35.0,  # High youth percentage\n",
    "        'internet_pct': 40.0,  # Low internet penetration\n",
    "        'polity': -5,  # Autocratic regime\n",
    "        'prev_events': 1  # Previous events\n",
    "    },\n",
    "    # Low risk case (high GDP, low unemployment, high polity, etc.)\n",
    "    {\n",
    "        'gdp': 40000,  # High GDP\n",
    "        'unemployment': 4.0,  # Low unemployment\n",
    "        'youth_pct': 18.0,  # Moderate youth percentage\n",
    "        'internet_pct': 85.0,  # High internet penetration\n",
    "        'polity': 8,  # Democratic regime\n",
    "        'prev_events': 0  # No previous events\n",
    "    },\n",
    "    # Malaysia case\n",
    "    {\n",
    "        'gdp': 11372,  # Malaysia GDP\n",
    "        'unemployment': 3.7,  # Malaysia unemployment\n",
    "        'youth_pct': 24.8,  # Malaysia youth percentage\n",
    "        'internet_pct': 89.6,  # Malaysia internet penetration\n",
    "        'polity': 8,  # Malaysia polity score\n",
    "        'prev_events': 0  # No previous events\n",
    "    }\n",
    "]\n",
    "\n",
    "# Process and predict for each test case\n",
    "results = []\n",
    "for i, case in enumerate(test_cases):\n",
    "    # Create feature vector\n",
    "    features = np.array([\n",
    "        np.log1p(case['gdp']),  # log_gdp\n",
    "        case['unemployment'],\n",
    "        case['youth_pct'],\n",
    "        case['internet_pct'],\n",
    "        case['polity'],\n",
    "        case['prev_events']\n",
    "    ]).reshape(1, -1)\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Predict\n",
    "    probability = best_model.predict_proba(features_scaled)[0, 1] if hasattr(best_model, \"predict_proba\") else best_model.decision_function(features_scaled)[0]\n",
    "    prediction = best_model.predict(features_scaled)[0]\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Case': i + 1,\n",
    "        'GDP': case['gdp'],\n",
    "        'Unemployment': case['unemployment'],\n",
    "        'Youth %': case['youth_pct'],\n",
    "        'Internet %': case['internet_pct'],\n",
    "        'Polity': case['polity'],\n",
    "        'Prev Events': case['prev_events'],\n",
    "        'Risk Score': probability,\n",
    "        'Prediction': 'High Risk' if prediction == 1 else 'Low Risk'\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Test Case Results:\")\n",
    "print(results_df.round(3))\n",
    "\n",
    "# Visualize risk scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(results_df)), results_df['Risk Score'], color=['red', 'green', 'orange'])\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7, label='Decision Threshold (0.5)')\n",
    "plt.title('Revolution Risk Scores for Test Cases')\n",
    "plt.xlabel('Test Case')\n",
    "plt.ylabel('Risk Score')\n",
    "plt.xticks(range(len(results_df)), ['High Risk Profile', 'Low Risk Profile', 'Malaysia'])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ## Model Interpretation\n",
    "\n",
    "# Feature importance\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Tree-based model\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    # Linear model\n",
    "    coefficients = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coefficient': best_model.coef_[0]\n",
    "    }).sort_values('coefficient', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['red' if coef < 0 else 'green' for coef in coefficients['coefficient']]\n",
    "    plt.barh(coefficients['feature'], coefficients['coefficient'], color=colors)\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.title('Feature Coefficients (Positive = Higher Risk)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ## Error Analysis\n",
    "\n",
    "# Get misclassified examples\n",
    "misclassified = X_test[y_test != y_pred].copy()\n",
    "misclassified['true_label'] = y_test[y_test != y_pred]\n",
    "misclassified['predicted_label'] = y_pred[y_test != y_pred]\n",
    "misclassified['probability'] = y_proba[y_test != y_pred]\n",
    "\n",
    "print(f\"Number of misclassified examples: {len(misclassified)}\")\n",
    "if len(misclassified) > 0:\n",
    "    print(\"\\nMisclassified examples:\")\n",
    "    print(misclassified.head(10))\n",
    "    \n",
    "    # Analyze patterns in misclassifications\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.hist(X_test[feature], alpha=0.5, label='All', bins=20)\n",
    "        plt.hist(misclassified[feature], alpha=0.5, label='Misclassified', bins=20)\n",
    "        plt.title(feature)\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ## Save Test Results\n",
    "\n",
    "results_df.to_csv('../data/test_case_results.csv', index=False)\n",
    "print(\"Test results saved to data/test_case_results.csv\")\n",
    "\n",
    "print(\"\\nModel testing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29bfca-4896-4d55-9ca3-3861111a9898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
