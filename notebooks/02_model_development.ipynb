{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570846fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from CSV files\n",
      "Training set: (724, 6)\n",
      "Test set: (406, 6)\n",
      "Class distribution in training set: {1: 690, 0: 37}\n",
      "Class distribution in test set: {1: 390, 0: 13}\n",
      "Training Logistic Regression model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [724, 727]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# Initialize and train model\u001b[39;00m\n\u001b[32m    102\u001b[39m logreg = LogisticRegression(\n\u001b[32m    103\u001b[39m     random_state=\u001b[32m42\u001b[39m, \n\u001b[32m    104\u001b[39m     class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    105\u001b[39m     max_iter=\u001b[32m1000\u001b[39m\n\u001b[32m    106\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[43mlogreg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[32m    110\u001b[39m y_pred_logreg = logreg.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/revolution_risk_predictor/venv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/revolution_risk_predictor/venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1247\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     _dtype = [np.float64, np.float32]\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mliblinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msag\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msaga\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1256\u001b[39m check_classification_targets(y)\n\u001b[32m   1257\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = np.unique(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/revolution_risk_predictor/venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/revolution_risk_predictor/venv/lib/python3.13/site-packages/sklearn/utils/validation.py:1387\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1368\u001b[39m X = check_array(\n\u001b[32m   1369\u001b[39m     X,\n\u001b[32m   1370\u001b[39m     accept_sparse=accept_sparse,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1382\u001b[39m     input_name=\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1383\u001b[39m )\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m-> \u001b[39m\u001b[32m1387\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/revolution_risk_predictor/venv/lib/python3.13/site-packages/sklearn/utils/validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [724, 727]"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: light\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.14.5\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# # Revolution Risk Predictor - Model Development\n",
    "# \n",
    "# This notebook handles model training, evaluation, and selection for the revolution risk prediction.\n",
    "\n",
    "# ## Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, average_precision_score, \n",
    "                             confusion_matrix, classification_report, RocCurveDisplay,\n",
    "                             PrecisionRecallDisplay)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# ## Generate Synthetic Data (if files don't exist)\n",
    "# This section creates synthetic data if the CSV files are missing\n",
    "\n",
    "try:\n",
    "    X_train = pd.read_csv('../data/X_train.csv')\n",
    "    X_test = pd.read_csv('../data/X_test.csv')\n",
    "    y_train = pd.read_csv('../data/y_train.csv').iloc[:, 0]\n",
    "    y_test = pd.read_csv('../data/y_test.csv').iloc[:, 0]\n",
    "    print(\"Loaded data from CSV files\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data files not found. Generating synthetic data...\")\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Create features\n",
    "    X = pd.DataFrame({\n",
    "        'log_gdp': np.random.normal(10, 1, n_samples),\n",
    "        'unemployment': np.random.uniform(2, 20, n_samples),\n",
    "        'youth_pct': np.random.uniform(15, 45, n_samples),\n",
    "        'internet_pct': np.random.uniform(30, 95, n_samples),\n",
    "        'polity': np.random.uniform(-10, 10, n_samples),\n",
    "        'prev_events': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])\n",
    "    })\n",
    "    \n",
    "    # Create target based on features (with some noise)\n",
    "    risk_score = (\n",
    "        (10 - X['polity']) * 0.1 +\n",
    "        X['unemployment'] * 0.05 +\n",
    "        X['youth_pct'] * 0.03 +\n",
    "        (100 - X['internet_pct']) * 0.01 +\n",
    "        (10 / X['log_gdp']) * 2 +\n",
    "        X['prev_events'] * 0.3 +\n",
    "        np.random.normal(0, 0.5, n_samples)\n",
    "    )\n",
    "    \n",
    "    y = (risk_score > 2.5).astype(int)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "    \n",
    "    print(\"Generated synthetic data\")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Class distribution in training set: {pd.Series(y_train).value_counts().to_dict()}\")\n",
    "print(f\"Class distribution in test set: {pd.Series(y_test).value_counts().to_dict()}\")\n",
    "\n",
    "# ## Model 1: Logistic Regression\n",
    "\n",
    "print(\"Training Logistic Regression model...\")\n",
    "\n",
    "# Initialize and train model\n",
    "logreg = LogisticRegression(\n",
    "    random_state=42, \n",
    "    class_weight='balanced',\n",
    "    max_iter=1000\n",
    ")\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "y_proba_logreg = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logreg))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logreg))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logreg))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_logreg))\n",
    "print(\"PR AUC:\", average_precision_score(y_test, y_proba_logreg))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_logreg)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Logistic Regression - Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "RocCurveDisplay.from_estimator(logreg, X_test, y_test)\n",
    "plt.title('Logistic Regression - ROC Curve')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "PrecisionRecallDisplay.from_estimator(logreg, X_test, y_test)\n",
    "plt.title('Logistic Regression - Precision-Recall Curve')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "joblib.dump(logreg, '../models/logistic_regression.joblib')\n",
    "print(\"Logistic Regression model saved!\")\n",
    "\n",
    "# ## Model 2: Random Forest\n",
    "\n",
    "print(\"\\nTraining Random Forest model...\")\n",
    "\n",
    "# Initialize and train model\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_estimators=100,\n",
    "    max_depth=10\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Random Forest Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_rf))\n",
    "print(\"PR AUC:\", average_precision_score(y_test, y_proba_rf))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Random Forest - Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "RocCurveDisplay.from_estimator(rf, X_test, y_test)\n",
    "plt.title('Random Forest - ROC Curve')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "PrecisionRecallDisplay.from_estimator(rf, X_test, y_test)\n",
    "plt.title('Random Forest - Precision-Recall Curve')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('Random Forest - Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "joblib.dump(rf, '../models/random_forest.joblib')\n",
    "print(\"Random Forest model saved!\")\n",
    "\n",
    "# ## Model Comparison\n",
    "\n",
    "# Create comparison dataframe\n",
    "models = ['Logistic Regression', 'Random Forest']\n",
    "accuracy = [accuracy_score(y_test, y_pred_logreg), accuracy_score(y_test, y_pred_rf)]\n",
    "precision = [precision_score(y_test, y_pred_logreg), precision_score(y_test, y_pred_rf)]\n",
    "recall = [recall_score(y_test, y_pred_logreg), recall_score(y_test, y_pred_rf)]\n",
    "f1 = [f1_score(y_test, y_pred_logreg), f1_score(y_test, y_pred_rf)]\n",
    "roc_auc = [roc_auc_score(y_test, y_proba_logreg), roc_auc_score(y_test, y_proba_rf)]\n",
    "pr_auc = [average_precision_score(y_test, y_proba_logreg), average_precision_score(y_test, y_proba_rf)]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1,\n",
    "    'ROC AUC': roc_auc,\n",
    "    'PR AUC': pr_auc\n",
    "}).set_index('Model')\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# Visual comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'PR AUC']\n",
    "comparison_df[metrics].plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Model Comparison - Performance Metrics')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ## Select Best Model\n",
    "\n",
    "# Based on PR AUC (most important for imbalanced classification)\n",
    "best_model_name = comparison_df['PR AUC'].idxmax()\n",
    "best_model = logreg if best_model_name == 'Logistic Regression' else rf\n",
    "\n",
    "print(f\"Best model based on PR AUC: {best_model_name}\")\n",
    "print(f\"PR AUC: {comparison_df.loc[best_model_name, 'PR AUC']:.3f}\")\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, '../models/best_model.joblib')\n",
    "print(\"Best model saved!\")\n",
    "\n",
    "print(\"\\nModel development completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d628caf-40fc-444a-a9a2-86c0d758696f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0d73b-223c-4fd5-9b2e-0c0518089eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64ab1c-0518-4d24-aa2b-0c4a4e08eec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c6ee5-4f8e-4714-a1bf-4c4f7807c132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedfee88-370f-4410-8d92-573cb43feece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
